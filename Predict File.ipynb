{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab1eb699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pefile\n",
    "import os\n",
    "import hashlib\n",
    "import array\n",
    "import math\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b7d1a1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_md5(fname):\n",
    "    hash_md5 = hashlib.md5()\n",
    "    with open(fname, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            hash_md5.update(chunk)\n",
    "    return hash_md5.hexdigest()\n",
    "\n",
    "def get_entropy(data):\n",
    "    if len(data) == 0:\n",
    "        return 0.0\n",
    "    occurences = array.array('L', [0]*256)\n",
    "    for x in data:\n",
    "        occurences[x if isinstance(x, int) else ord(x)] += 1\n",
    "\n",
    "    entropy = 0\n",
    "    for x in occurences:\n",
    "        if x:\n",
    "            p_x = float(x) / len(data)       \n",
    "            entropy -= p_x*math.log(p_x, 2)\n",
    "    return entropy\n",
    "\n",
    "def get_resources(pe):\n",
    "    \"\"\"Extract resources :\n",
    "    [entropy, size]\"\"\"\n",
    "    resources = []\n",
    "    if hasattr(pe, 'DIRECTORY_ENTRY_RESOURCE'):\n",
    "        try:\n",
    "            for resource_type in pe.DIRECTORY_ENTRY_RESOURCE.entries:\n",
    "                if hasattr(resource_type, 'directory'):\n",
    "                    for resource_id in resource_type.directory.entries:\n",
    "                        if hasattr(resource_id, 'directory'):\n",
    "                            for resource_lang in resource_id.directory.entries:\n",
    "                                data = pe.get_data(resource_lang.data.struct.OffsetToData, resource_lang.data.struct.Size)\n",
    "                                size = resource_lang.data.struct.Size\n",
    "                                entropy = get_entropy(data)\n",
    "\n",
    "                                resources.append([entropy, size])\n",
    "        except Exception as e:\n",
    "            return resources\n",
    "    return resources\n",
    "\n",
    "def get_version_info(pe):\n",
    "    \"\"\"Return version infos\"\"\"\n",
    "    res = {}\n",
    "    for fileinfo in pe.FileInfo:\n",
    "        if fileinfo.Key == 'StringFileInfo':\n",
    "            for st in fileinfo.StringTable:\n",
    "                for entry in st.entries.items():\n",
    "                    res[entry[0]] = entry[1]\n",
    "        if fileinfo.Key == 'VarFileInfo':\n",
    "            for var in fileinfo.Var:\n",
    "                res[var.entry.items()[0][0]] = var.entry.items()[0][1]\n",
    "    if hasattr(pe, 'VS_FIXEDFILEINFO'):\n",
    "          res['flags'] = pe.VS_FIXEDFILEINFO.FileFlags\n",
    "          res['os'] = pe.VS_FIXEDFILEINFO.FileOS\n",
    "          res['type'] = pe.VS_FIXEDFILEINFO.FileType\n",
    "          res['file_version'] = pe.VS_FIXEDFILEINFO.FileVersionLS\n",
    "          res['product_version'] = pe.VS_FIXEDFILEINFO.ProductVersionLS\n",
    "          res['signature'] = pe.VS_FIXEDFILEINFO.Signature\n",
    "          res['struct_version'] = pe.VS_FIXEDFILEINFO.StrucVersion\n",
    "    return res\n",
    "\n",
    "def extract_infos(fpath):\n",
    "    res = []\n",
    "    res.append(get_md5(fpath))\n",
    "    pe = pefile.PE(fpath)\n",
    "    res.append(pe.FILE_HEADER.Machine)\n",
    "    res.append(pe.FILE_HEADER.SizeOfOptionalHeader)\n",
    "    res.append(pe.FILE_HEADER.Characteristics)\n",
    "    res.append(pe.OPTIONAL_HEADER.MajorLinkerVersion)\n",
    "    res.append(pe.OPTIONAL_HEADER.MinorLinkerVersion)\n",
    "    res.append(pe.OPTIONAL_HEADER.SizeOfCode)\n",
    "    res.append(pe.OPTIONAL_HEADER.SizeOfInitializedData)\n",
    "    res.append(pe.OPTIONAL_HEADER.SizeOfUninitializedData)\n",
    "    res.append(pe.OPTIONAL_HEADER.AddressOfEntryPoint)\n",
    "    res.append(pe.OPTIONAL_HEADER.BaseOfCode)\n",
    "    try:\n",
    "        res.append(pe.OPTIONAL_HEADER.BaseOfData)\n",
    "    except AttributeError:\n",
    "        res.append(0)\n",
    "    res.append(pe.OPTIONAL_HEADER.ImageBase)\n",
    "    res.append(pe.OPTIONAL_HEADER.SectionAlignment)\n",
    "    res.append(pe.OPTIONAL_HEADER.FileAlignment)\n",
    "    res.append(pe.OPTIONAL_HEADER.MajorOperatingSystemVersion)\n",
    "    res.append(pe.OPTIONAL_HEADER.MinorOperatingSystemVersion)\n",
    "    res.append(pe.OPTIONAL_HEADER.MajorImageVersion)\n",
    "    res.append(pe.OPTIONAL_HEADER.MinorImageVersion)\n",
    "    res.append(pe.OPTIONAL_HEADER.MajorSubsystemVersion)\n",
    "    res.append(pe.OPTIONAL_HEADER.MinorSubsystemVersion)\n",
    "    res.append(pe.OPTIONAL_HEADER.SizeOfImage)\n",
    "    res.append(pe.OPTIONAL_HEADER.SizeOfHeaders)\n",
    "    res.append(pe.OPTIONAL_HEADER.CheckSum)\n",
    "    res.append(pe.OPTIONAL_HEADER.Subsystem)\n",
    "    res.append(pe.OPTIONAL_HEADER.DllCharacteristics)\n",
    "    res.append(pe.OPTIONAL_HEADER.SizeOfStackReserve)\n",
    "    res.append(pe.OPTIONAL_HEADER.SizeOfStackCommit)\n",
    "    res.append(pe.OPTIONAL_HEADER.SizeOfHeapReserve)\n",
    "    res.append(pe.OPTIONAL_HEADER.SizeOfHeapCommit)\n",
    "    res.append(pe.OPTIONAL_HEADER.LoaderFlags)\n",
    "    res.append(pe.OPTIONAL_HEADER.NumberOfRvaAndSizes)\n",
    "    res.append(len(pe.sections))\n",
    "    list_pe_sections = []\n",
    "    for i in pe.sections:\n",
    "        list_pe_sections.append(i)\n",
    "    entropy = list(map(lambda x:x.get_entropy(), list_pe_sections))\n",
    "    res.append(sum(entropy)/float(len(list(entropy))))\n",
    "    res.append(min(entropy))\n",
    "    res.append(max(entropy))\n",
    "    \n",
    "    raw_sizes = list(map(lambda x:x.SizeOfRawData, list_pe_sections))\n",
    "    res.append(sum(raw_sizes)/float(len(list(raw_sizes))))\n",
    "    res.append(min(raw_sizes))\n",
    "    res.append(max(raw_sizes))\n",
    "    virtual_sizes = list(map(lambda x:x.Misc_VirtualSize, list_pe_sections))\n",
    "    res.append(sum(virtual_sizes)/float(len(virtual_sizes)))\n",
    "    res.append(min(virtual_sizes))\n",
    "    res.append(max(virtual_sizes))\n",
    "    #Imports\n",
    "    try:\n",
    "        res.append(len(pe.DIRECTORY_ENTRY_IMPORT))\n",
    "        imports = sum([x.imports for x in pe.DIRECTORY_ENTRY_IMPORT], [])\n",
    "        res.append(len(imports))\n",
    "        res.append(len(list(filter(lambda x:x.name is None, imports))))\n",
    "    except AttributeError:\n",
    "        res.append(0)\n",
    "        res.append(0)\n",
    "        res.append(0)\n",
    "    #Exports\n",
    "    try:\n",
    "        res.append(len(pe.DIRECTORY_ENTRY_EXPORT.symbols))\n",
    "    except AttributeError:\n",
    "        # No export\n",
    "        res.append(0)\n",
    "    #Resources\n",
    "    resources= get_resources(pe)\n",
    "    res.append(len(resources))\n",
    "    if len(resources)> 0:\n",
    "        list_resources = []\n",
    "        for i in resources:\n",
    "            list_resources.append(i)\n",
    "        entropy = list(map(lambda x:x[0], list_resources))\n",
    "        res.append(sum(entropy)/float(len(list(entropy))))\n",
    "        res.append(min(entropy))\n",
    "        res.append(max(entropy))\n",
    "        sizes = list(map(lambda x:x[1], list_resources))\n",
    "        res.append(sum(sizes)/float(len(list(sizes))))\n",
    "        res.append(min(sizes))\n",
    "        res.append(max(sizes))\n",
    "    else:\n",
    "        res.append(0)\n",
    "        res.append(0)\n",
    "        res.append(0)\n",
    "        res.append(0)\n",
    "        res.append(0)\n",
    "        res.append(0)\n",
    "\n",
    "    # Load configuration size\n",
    "    try:\n",
    "        res.append(pe.DIRECTORY_ENTRY_LOAD_CONFIG.struct.Size)\n",
    "    except AttributeError:\n",
    "        res.append(0)\n",
    "\n",
    "    # Version configuration size\n",
    "    try:\n",
    "        version_infos = get_version_info(pe)\n",
    "        res.append(len(version_infos.keys()))\n",
    "    except AttributeError:\n",
    "        res.append(0)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "53e45437",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "    \"md5\",\n",
    "    \"Machine\",\n",
    "    \"SizeOfOptionalHeader\",\n",
    "    \"Characteristics\",\n",
    "    \"MajorLinkerVersion\",\n",
    "    \"MinorLinkerVersion\",\n",
    "    \"SizeOfCode\",\n",
    "    \"SizeOfInitializedData\",\n",
    "    \"SizeOfUninitializedData\",\n",
    "    \"AddressOfEntryPoint\",\n",
    "    \"BaseOfCode\",\n",
    "    \"BaseOfData\",\n",
    "    \"ImageBase\",\n",
    "    \"SectionAlignment\",\n",
    "    \"FileAlignment\",\n",
    "    \"MajorOperatingSystemVersion\",\n",
    "    \"MinorOperatingSystemVersion\",\n",
    "    \"MajorImageVersion\",\n",
    "    \"MinorImageVersion\",\n",
    "    \"MajorSubsystemVersion\",\n",
    "    \"MinorSubsystemVersion\",\n",
    "    \"SizeOfImage\",\n",
    "    \"SizeOfHeaders\",\n",
    "    \"CheckSum\",\n",
    "    \"Subsystem\",\n",
    "    \"DllCharacteristics\",\n",
    "    \"SizeOfStackReserve\",\n",
    "    \"SizeOfStackCommit\",\n",
    "    \"SizeOfHeapReserve\",\n",
    "    \"SizeOfHeapCommit\",\n",
    "    \"LoaderFlags\",\n",
    "    \"NumberOfRvaAndSizes\",\n",
    "    \"SectionsNb\",\n",
    "    \"SectionsMeanEntropy\",\n",
    "    \"SectionsMinEntropy\",\n",
    "    \"SectionsMaxEntropy\",\n",
    "    \"SectionsMeanRawsize\",\n",
    "    \"SectionsMinRawsize\",\n",
    "    \"SectionMaxRawsize\",\n",
    "    \"SectionsMeanVirtualsize\",\n",
    "    \"SectionsMinVirtualsize\",\n",
    "    \"SectionMaxVirtualsize\",\n",
    "    \"ImportsNbDLL\",\n",
    "    \"ImportsNb\",\n",
    "    \"ImportsNbOrdinal\",\n",
    "    \"ExportNb\",\n",
    "    \"ResourcesNb\",\n",
    "    \"ResourcesMeanEntropy\",\n",
    "    \"ResourcesMinEntropy\",\n",
    "    \"ResourcesMaxEntropy\",\n",
    "    \"ResourcesMeanSize\",\n",
    "    \"ResourcesMinSize\",\n",
    "    \"ResourcesMaxSize\",\n",
    "    \"LoadConfigurationSize\",\n",
    "    \"VersionInformationSize\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fc567f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9f102f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = joblib.load('rf_model.pkl')\n",
    "test_features = extract_infos('path of file to be checked')\n",
    "\n",
    "len(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2af91e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the features to a pandas DataFrame with a single row\n",
    "test_df = pd.DataFrame([test_features], columns=feature_names)\n",
    "le = LabelEncoder()\n",
    "test_df['md5'] = le.fit_transform(test_df['md5'])\n",
    "# Use the loaded model to make a prediction on the test file\n",
    "prediction = rf_model.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "36b29c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legitimate\n"
     ]
    }
   ],
   "source": [
    "if prediction[0]==0:\n",
    "    print(\"Malicious\")\n",
    "else:\n",
    "    print(\"Legitimate\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
